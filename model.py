import torch
import torch.nn as nn


class MultiHeadAttention(nn.Module):

    def __init__(self):
        pass


class LayerNorm(nn.Module):

    def __init__(self):
        pass


class GELU(nn.Module):

    def __init__(self):
        pass


class FeedForward(nn.Module):

    def __init__(self):
        pass


class LayerNorm(nn.Module):

    def __init__(self):
        pass


class TransformerBlock(nn.Module):

    def __init__(self):
        pass


class GPT(nn.Module):

    def __init__(self):
        pass
